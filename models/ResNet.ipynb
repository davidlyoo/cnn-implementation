{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:20:34.431469Z",
     "start_time": "2024-11-11T09:20:34.427020Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-09T13:38:36.183053Z",
     "iopub.status.busy": "2024-11-09T13:38:36.180080Z",
     "iopub.status.idle": "2024-11-09T13:38:36.191538Z",
     "shell.execute_reply": "2024-11-09T13:38:36.190567Z",
     "shell.execute_reply.started": "2024-11-09T13:38:36.182963Z"
    },
    "id": "GAC9sWkdBKGR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:20:35.348321Z",
     "start_time": "2024-11-11T09:20:35.340862Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-09T13:54:53.260282Z",
     "iopub.status.busy": "2024-11-09T13:54:53.259680Z",
     "iopub.status.idle": "2024-11-09T13:54:54.623260Z",
     "shell.execute_reply": "2024-11-09T13:54:54.621905Z",
     "shell.execute_reply.started": "2024-11-09T13:54:53.260250Z"
    },
    "id": "BauBkbLmBOJM",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cuda\n"
     ]
    }
   ],
   "source": [
    "seed = 2024\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "cudnn.deterministic = True\n",
    "cudnn.benchmark = False\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:20:38.843901Z",
     "start_time": "2024-11-11T09:20:36.302538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, \n",
    "                                 download=True,\n",
    "                                 transform=transform_train)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                download=True,\n",
    "                                transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:20:38.948952Z",
     "start_time": "2024-11-11T09:20:38.940706Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "validation_size = len(train_dataset) - train_size\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(train_dataset, [train_size, validation_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:20:41.223249Z",
     "start_time": "2024-11-11T09:20:41.158169Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:32:36.633133Z",
     "start_time": "2024-11-11T09:32:36.620921Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:32:37.920011Z",
     "start_time": "2024-11-11T09:32:37.910471Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-09T14:00:58.817523Z",
     "iopub.status.busy": "2024-11-09T14:00:58.816654Z",
     "iopub.status.idle": "2024-11-09T14:00:59.440627Z",
     "shell.execute_reply": "2024-11-09T14:00:59.439555Z",
     "shell.execute_reply.started": "2024-11-09T14:00:58.817447Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:32:38.174004Z",
     "start_time": "2024-11-11T09:32:38.163259Z"
    }
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:32:40.237382Z",
     "start_time": "2024-11-11T09:32:40.230634Z"
    }
   },
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
    "\n",
    "def ResNet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def ResNet50():\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "\n",
    "def ResNet101():\n",
    "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
    "\n",
    "def ResNet152():\n",
    "    return ResNet(Bottleneck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:32:41.748321Z",
     "start_time": "2024-11-11T09:32:41.548653Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ResNet18().to(device)\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:42:04.992769Z",
     "start_time": "2024-11-11T09:32:45.886438Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-09T14:00:59.442289Z",
     "iopub.status.busy": "2024-11-09T14:00:59.441836Z",
     "iopub.status.idle": "2024-11-09T14:05:44.169993Z",
     "shell.execute_reply": "2024-11-09T14:05:44.168796Z",
     "shell.execute_reply.started": "2024-11-09T14:00:59.442261Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Epoch [1/30]\n",
      "     Train Loss: 1.5301\n",
      "Validation Loss: 1.4354\n",
      "      Train_acc: 43.69%\n",
      "        Val_acc: 45.54%\n",
      "\n",
      "        Epoch [2/30]\n",
      "     Train Loss: 1.1071\n",
      "Validation Loss: 1.4822\n",
      "      Train_acc: 60.15%\n",
      "        Val_acc: 46.81%\n",
      "\n",
      "        Epoch [3/30]\n",
      "     Train Loss: 0.9394\n",
      "Validation Loss: 0.9763\n",
      "      Train_acc: 66.94%\n",
      "        Val_acc: 66.36%\n",
      "\n",
      "        Epoch [4/30]\n",
      "     Train Loss: 0.8210\n",
      "Validation Loss: 1.0260\n",
      "      Train_acc: 71.19%\n",
      "        Val_acc: 65.90%\n",
      "\n",
      "        Epoch [5/30]\n",
      "     Train Loss: 0.7299\n",
      "Validation Loss: 0.8826\n",
      "      Train_acc: 74.85%\n",
      "        Val_acc: 68.85%\n",
      "\n",
      "        Epoch [6/30]\n",
      "     Train Loss: 0.6721\n",
      "Validation Loss: 0.8856\n",
      "      Train_acc: 76.95%\n",
      "        Val_acc: 69.89%\n",
      "\n",
      "        Epoch [7/30]\n",
      "     Train Loss: 0.6162\n",
      "Validation Loss: 0.7921\n",
      "      Train_acc: 78.97%\n",
      "        Val_acc: 73.34%\n",
      "\n",
      "        Epoch [8/30]\n",
      "     Train Loss: 0.5712\n",
      "Validation Loss: 0.7395\n",
      "      Train_acc: 80.62%\n",
      "        Val_acc: 75.99%\n",
      "\n",
      "        Epoch [9/30]\n",
      "     Train Loss: 0.5262\n",
      "Validation Loss: 0.6372\n",
      "      Train_acc: 82.03%\n",
      "        Val_acc: 78.71%\n",
      "\n",
      "        Epoch [10/30]\n",
      "     Train Loss: 0.4969\n",
      "Validation Loss: 0.6557\n",
      "      Train_acc: 83.07%\n",
      "        Val_acc: 77.72%\n",
      "\n",
      "        Epoch [11/30]\n",
      "     Train Loss: 0.4596\n",
      "Validation Loss: 0.5848\n",
      "      Train_acc: 84.34%\n",
      "        Val_acc: 80.40%\n",
      "\n",
      "        Epoch [12/30]\n",
      "     Train Loss: 0.4327\n",
      "Validation Loss: 0.5646\n",
      "      Train_acc: 85.25%\n",
      "        Val_acc: 81.41%\n",
      "\n",
      "        Epoch [13/30]\n",
      "     Train Loss: 0.3991\n",
      "Validation Loss: 0.5513\n",
      "      Train_acc: 86.56%\n",
      "        Val_acc: 81.72%\n",
      "\n",
      "        Epoch [14/30]\n",
      "     Train Loss: 0.3768\n",
      "Validation Loss: 0.4574\n",
      "      Train_acc: 87.25%\n",
      "        Val_acc: 84.75%\n",
      "\n",
      "        Epoch [15/30]\n",
      "     Train Loss: 0.3518\n",
      "Validation Loss: 0.4446\n",
      "      Train_acc: 88.09%\n",
      "        Val_acc: 85.34%\n",
      "\n",
      "        Epoch [16/30]\n",
      "     Train Loss: 0.3231\n",
      "Validation Loss: 0.4424\n",
      "      Train_acc: 89.02%\n",
      "        Val_acc: 85.48%\n",
      "\n",
      "        Epoch [17/30]\n",
      "     Train Loss: 0.2977\n",
      "Validation Loss: 0.3725\n",
      "      Train_acc: 90.03%\n",
      "        Val_acc: 87.34%\n",
      "\n",
      "        Epoch [18/30]\n",
      "     Train Loss: 0.2751\n",
      "Validation Loss: 0.4000\n",
      "      Train_acc: 90.87%\n",
      "        Val_acc: 86.71%\n",
      "\n",
      "        Epoch [19/30]\n",
      "     Train Loss: 0.2478\n",
      "Validation Loss: 0.4353\n",
      "      Train_acc: 91.74%\n",
      "        Val_acc: 85.24%\n",
      "\n",
      "        Epoch [20/30]\n",
      "     Train Loss: 0.2231\n",
      "Validation Loss: 0.3378\n",
      "      Train_acc: 92.44%\n",
      "        Val_acc: 88.50%\n",
      "\n",
      "        Epoch [21/30]\n",
      "     Train Loss: 0.2040\n",
      "Validation Loss: 0.3431\n",
      "      Train_acc: 93.02%\n",
      "        Val_acc: 88.65%\n",
      "\n",
      "        Epoch [22/30]\n",
      "     Train Loss: 0.1754\n",
      "Validation Loss: 0.3297\n",
      "      Train_acc: 94.11%\n",
      "        Val_acc: 89.05%\n",
      "\n",
      "        Epoch [23/30]\n",
      "     Train Loss: 0.1543\n",
      "Validation Loss: 0.3196\n",
      "      Train_acc: 94.94%\n",
      "        Val_acc: 89.50%\n",
      "\n",
      "        Epoch [24/30]\n",
      "     Train Loss: 0.1361\n",
      "Validation Loss: 0.3063\n",
      "      Train_acc: 95.52%\n",
      "        Val_acc: 90.09%\n",
      "\n",
      "        Epoch [25/30]\n",
      "     Train Loss: 0.1160\n",
      "Validation Loss: 0.2914\n",
      "      Train_acc: 96.23%\n",
      "        Val_acc: 90.75%\n",
      "\n",
      "        Epoch [26/30]\n",
      "     Train Loss: 0.0994\n",
      "Validation Loss: 0.2846\n",
      "      Train_acc: 96.84%\n",
      "        Val_acc: 91.01%\n",
      "\n",
      "        Epoch [27/30]\n",
      "     Train Loss: 0.0867\n",
      "Validation Loss: 0.2840\n",
      "      Train_acc: 97.26%\n",
      "        Val_acc: 91.25%\n",
      "\n",
      "        Epoch [28/30]\n",
      "     Train Loss: 0.0817\n",
      "Validation Loss: 0.2892\n",
      "      Train_acc: 97.45%\n",
      "        Val_acc: 91.16%\n",
      "\n",
      "        Epoch [29/30]\n",
      "     Train Loss: 0.0725\n",
      "Validation Loss: 0.2841\n",
      "      Train_acc: 97.83%\n",
      "        Val_acc: 91.28%\n",
      "\n",
      "        Epoch [30/30]\n",
      "     Train Loss: 0.0689\n",
      "Validation Loss: 0.2773\n",
      "      Train_acc: 98.00%\n",
      "        Val_acc: 91.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "#def train(epoch):\n",
    "for epoch in range(num_epochs):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    train_loss = 0.0\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "    print(f'        Epoch [{epoch+1}/{num_epochs}]')\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = 100. * correct / total\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_total = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to('cuda'), labels.to('cuda')\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    val_loss /= len(validation_loader)\n",
    "    val_accuracy = 100. * val_correct / val_total\n",
    "\n",
    "    print(f'     Train Loss: {train_loss:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}')\n",
    "    print(f'      Train_acc: {train_accuracy:.2f}%')\n",
    "    print(f'        Val_acc: {val_accuracy:.2f}%\\n')\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T09:42:47.013481Z",
     "start_time": "2024-11-11T09:42:44.302927Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-12T05:37:02.046233Z",
     "iopub.status.busy": "2024-11-12T05:37:02.045046Z",
     "iopub.status.idle": "2024-11-12T05:37:02.352750Z",
     "shell.execute_reply": "2024-11-12T05:37:02.350761Z",
     "shell.execute_reply.started": "2024-11-12T05:37:02.046151Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# test\u001b[39;00m\n\u001b[1;32m      2\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# test\n",
    "correct = 0\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100.* correct / len(test_loader.dataset):.2f} %')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
